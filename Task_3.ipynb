{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTZVdeop0en/PU9pydmo4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Winner121353/Deep_Learning_Assignment/blob/master/Task_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw503JGDEOZR",
        "colab_type": "text"
      },
      "source": [
        "# Task-3(Deep Learning Assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX8VYQTlEOO0",
        "colab_type": "text"
      },
      "source": [
        "Problem : Using Tensor flow, write and test the back propagation algorithm using the steps of the algorithm. Use only Tensor flow based code lines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PVDvtbaEiYx",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8d4_wIMusXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81971305-f12b-43a5-9658-bb480021e382"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjWpHpOiEk2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0607efbc-7667-44a7-f6c8-9c5a62eb6a7a"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEI5Uj0j7mta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "5776545f-52e3-4b0e-cefd-e7a5e2bea385"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-6a1341729886>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gguuUaY7pdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_nodes_hl1 = 500\n",
        "n_nodes_hl2 = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIGKSZ3v7wYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MofcqQMN7yQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder('float', [None, 784])\n",
        "y = tf.placeholder('float', [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvfR9md9A_ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def d_tf_tanh(x):\n",
        "  return tf.subtract(tf.constant(1.0),tf.square(tf.tanh(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B788YJ1b70ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_1_layer = {'weights':tf.Variable(tf.random_normal([784, n_nodes_hl1])),\n",
        "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
        "hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
        "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
        "\n",
        "   \n",
        "\n",
        "z1 = tf.add(tf.matmul(x,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
        "a1 = tf.tanh(z1)\n",
        "\n",
        "z2 = tf.add(tf.matmul(a1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
        "a2 = tf.sigmoid(z2)\n",
        "\n",
        "\n",
        "d_z2 = tf.subtract(a2,y)\n",
        "d_b2 = d_z2\n",
        "d_W2 = tf.matmul(tf.transpose(a1),d_z2)\n",
        "d_a1 = tf.matmul(d_z2, tf.transpose(hidden_2_layer['weights']))\n",
        "d_z1 = tf.multiply(d_tf_tanh(z1), d_a1)\n",
        "d_b1 = d_z1\n",
        "d_W1 = tf.matmul(tf.transpose(x), d_z1) \n",
        "\n",
        "lr = tf.constant(0.01)#learning_rate\n",
        "    \n",
        "\n",
        "    #Gradient_Descent_Optimizer\n",
        "optimizer = [\n",
        "                 tf.assign(hidden_1_layer['weights'],tf.subtract(hidden_1_layer['weights'], tf.multiply(lr, d_W1))),\n",
        "                 tf.assign(hidden_1_layer['biases'],tf.subtract(hidden_1_layer['biases'], tf.multiply(lr, tf.reduce_mean(d_b1, axis = [0])))),\n",
        "                 tf.assign(hidden_2_layer['weights'],tf.subtract(hidden_2_layer['weights'], tf.multiply(lr, d_W2))),\n",
        "                 tf.assign(hidden_2_layer['biases'],tf.subtract(hidden_2_layer['biases'],tf.multiply(lr, tf.reduce_mean(d_b2, axis = [0]))))\n",
        "                 \n",
        "    ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7IRCwSrEsug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "07e1db3b-a489-4722-832f-1baee22809e9"
      },
      "source": [
        "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=a2,labels=y) )\n",
        "hm_epochs = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "\n",
        "    for epoch in range(hm_epochs):\n",
        "          epoch_loss = 1\n",
        "          for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "              epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
        "              _, c = sess.run([optimizer,cost], feed_dict={x: epoch_x, y: epoch_y})\n",
        "              epoch_loss += c\n",
        "\n",
        "          print('Epoch', epoch, 'completed out of',hm_epochs,'loss:',epoch_loss)\n",
        "\n",
        "    correct = tf.equal(tf.argmax(a2, 1), tf.argmax(y, 1))\n",
        "\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
        "    print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 completed out of 10 loss: 895.059629201889\n",
            "Epoch 1 completed out of 10 loss: 854.2877017259598\n",
            "Epoch 2 completed out of 10 loss: 841.4782778024673\n",
            "Epoch 3 completed out of 10 loss: 834.1571977138519\n",
            "Epoch 4 completed out of 10 loss: 828.0129742622375\n",
            "Epoch 5 completed out of 10 loss: 824.0117610692978\n",
            "Epoch 6 completed out of 10 loss: 820.7783236503601\n",
            "Epoch 7 completed out of 10 loss: 816.9283475875854\n",
            "Epoch 8 completed out of 10 loss: 813.9969700574875\n",
            "Epoch 9 completed out of 10 loss: 812.0129739046097\n",
            "Accuracy: 0.9609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVTpH_7nFpDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}